# -*- coding: utf-8 -*-
"""COVID-19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ujCMQvFJ0VxMZB3Ie8pn4mTvBNlnK7er
"""

# Download dataset
import os
os.environ['KAGGLE_USERNAME'] = "ashiishkarhade" # username from the json file
os.environ['KAGGLE_KEY'] = "b1a95537e1f638d722d282d16825c7a7" # key from the json file
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia
!unzip chest-xray-pneumonia.zip
!git clone https://github.com/ieee8023/covid-chestxray-dataset.git

import pandas as pd

FILE_PATH = 'chestxray/metadata.csv'
IMAGE_PATH = 'chestxray/images'

df = pd.read_csv(FILE_PATH)
print(df.shape)

df.head()

import os

os.mkdir('dataset')
# COVID IMAGE FOLDER
TARGET_DIR = 'dataset/covid'
if not os.path.exists(TARGET_DIR):
    os.mkdir(TARGET_DIR)

# NORMAL IMAGES FOLDER
TARGET_DIR_NORMAL = 'dataset/normal'
if not os.path.exists(TARGET_DIR_NORMAL):
    os.mkdir(TARGET_DIR_NORMAL)

import shutil
cnt = 0
for (i, rows) in df.iterrows():
    if rows["finding"] == "COVID-19" and rows["view"]=="PA":
        filename = rows['filename']
        image_path = os.path.join(IMAGE_PATH, filename)
        target_copy_path = os.path.join(TARGET_DIR, filename)
        shutil.copy2(image_path, target_copy_path)

# SAMPLING IMAGES FROM KAGGLE DATASet
import random
KAGGLE_PATH = '/content/chest_xray/train/NORMAL'

image_names = os.listdir(KAGGLE_PATH)
random.shuffle(image_names)

for i in range(142):
    image_name = image_names[i]
    img_path = os.path.join(KAGGLE_PATH, image_name)
    targ_path = os.path.join(TARGET_DIR_NORMAL, image_name)
    shutil.copy2(img_path, targ_path)

# TRAIN_TEST_SPLIT INTO TWO FOLDERS
# TRAIN -> COVID, NORMAL
# VAL -> COVID, NORMAL
os.mkdir('dataset/train')
os.mkdir('dataset/val')
os.mkdir('dataset/train/normal')
os.mkdir('dataset/val/normal')
os.mkdir('dataset/train/covid')
os.mkdir('dataset/val/covid')

train_dir = 'dataset/train'
val_dir = 'dataset/val'

from PIL import Image
normals = os.listdir('dataset/normal')
covs = os.listdir('dataset/covid')
TRAINING_SPLIT = 112

train_normal = normals[:TRAINING_SPLIT]
test_normal = normals[TRAINING_SPLIT:]
train_covid = covs[:TRAINING_SPLIT]
test_covid = covs[TRAINING_SPLIT:]

for filename in train_normal:
    img_pth = os.path.join('dataset/normal', filename)
    target_pth = os.path.join('dataset/train/normal', filename)
    shutil.copy2(img_pth, target_pth)

for filename in test_normal:
    img_pth = os.path.join('dataset/normal', filename)
    target_pth = os.path.join('dataset/val/normal', filename)
    shutil.copy2(img_pth, target_pth)

for filename in train_covid:
    img_pth = os.path.join('dataset/covid', filename)
    target_pth = os.path.join('dataset/train/covid', filename)
    shutil.copy2(img_pth, target_pth)

for filename in test_covid:
    img_pth = os.path.join('dataset/covid', filename)
    target_pth = os.path.join('dataset/val/covid', filename)
    shutil.copy2(img_pth, target_pth)

# deleting every other folders 
shutil.rmtree('chest_xray')
shutil.rmtree('chestxray')
shutil.rmtree('dataset/covid')
shutil.rmtree('dataset/normal')

import numpy as np
import matplotlib.pyplot as plt
import keras
import tensorflow as tf
from keras.layers import *
from keras.models import *
from keras.preprocessing import image

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True
)

test_datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True
)

train_generator = train_datagen.flow_from_directory(
    'dataset/train',
    target_size = (224,224),
    batch_size=32,
    class_mode = 'binary'
)

test_generator = test_datagen.flow_from_directory(
    'dataset/val',
    target_size = (224,224),
    batch_size=32,
    class_mode = 'binary'
)

train_generator.class_indices

# CNN BASED MODEL

model = Sequential([
                    # BLOCK 1
                    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (224, 224, 3)),
                    Conv2D(64, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # BLOCK 2
                    Conv2D(128, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # BLOCK 3
                    Conv2D(128, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # BLOCK 4
                    Conv2D(264, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # block 5
                    Flatten(),
                    Dense(64, activation='relu'),
                    Dropout(0.5),
                    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

history = model.fit_generator(
    train_generator,
    steps_per_epoch = 8,
    epochs = 10,
    validation_data = test_generator,
    validation_steps = 2
)

